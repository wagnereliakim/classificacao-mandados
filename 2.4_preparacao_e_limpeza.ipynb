{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import re\n",
    "import unidecode\n",
    "import csv\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "import string\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "#bokeh plotting\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show, figure\n",
    "\n",
    "import spacy\n",
    "#!python -m spacy download pt_core_news_lg\n",
    "nlp = spacy.load('pt_core_news_lg')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import MWETokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70200, 18)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_csv = '../dados/amostra.sample.1.com_texto.sem_header.csv'\n",
    "\n",
    "ALL_DATA = True\n",
    "\n",
    "df = pd.read_csv(original_csv)\n",
    "\n",
    "if ALL_DATA:\n",
    "    for sample in range(2, 10 + 1):\n",
    "        original_csv = '../dados/amostra.sample.{}.com_texto.sem_header.csv'.format(sample)\n",
    "        df_adicional = pd.read_csv(original_csv)\n",
    "        df = pd.concat([df, df_adicional], ignore_index=True)\n",
    "\n",
    "#df = df.sample(n=200, random_state=42, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a text file with special stop words\n",
    "with open('stopwords.txt', 'r') as f:\n",
    "    str_f = f.read()\n",
    "    stopwords_file = set(str_f.split('\\n'))\n",
    "all_stopwords = stopwords.words('portuguese') + list(stopwords_file)\n",
    "\n",
    "def remove_stop_words(texto):\n",
    "    sem_stop = [w for w in texto.split() if w not in all_stopwords]\n",
    "    return \" \".join(sem_stop)\n",
    "\n",
    "def custom_tokenizer(texto):\n",
    "    mwtokenizer = MWETokenizer()\n",
    "    mwtokenizer.add_mwe(('#', 'mail'))\n",
    "    mwtokenizer.add_mwe(('#', 'weblink'))\n",
    "    mwtokenizer.add_mwe(('#', 'phone'))\n",
    "    mwtokenizer.add_mwe(('#', 'processo'))\n",
    "    mwtokenizer.add_mwe(('#', 'currency'))\n",
    "    mwtokenizer.add_mwe(('#', 'cep'))\n",
    "    mwtokenizer.add_mwe(('#', 'date'))\n",
    "    mwtokenizer.add_mwe(('#', 'ordinal'))\n",
    "    mwtokenizer.add_mwe(('#', 'number'))\n",
    "    mwtokenizer.add_mwe(('boa', 'vista'))\n",
    "    mwtokenizer.add_mwe(('boa', 'vista/rr'))\n",
    "    mwtokenizer.add_mwe(('boa', 'viagem'))\n",
    "    mwtokenizer.add_mwe(('vara', 'civel'))\n",
    "    return mwtokenizer.tokenize(word_tokenize(texto, language='portuguese'))\n",
    "\n",
    "def stemm(texto):\n",
    "    stemmer = RSLPStemmer()\n",
    "    return \" \".join([str(stemmer.stem(p)) for p in texto.split()])\n",
    "\n",
    "def lemmatize(texto):\n",
    "    result = \" \".join([w.lemma_ for w in nlp(texto)])\n",
    "    result=re.sub(\" # _ \", ' #_', result)\n",
    "    result=re.sub('\\s{2,}', ' ', result) #removendo espaços duplicados\n",
    "    return result.lower()\n",
    "\n",
    "def preprocessor_OLD(texto, replace_email=True, replace_url=True, replace_numbers=True, to_lower=True, replace_stop_words=True, replace_accents=True):\n",
    "    email_replacer = ' mail### '\n",
    "    url_replacer = ' weblink### '\n",
    "    number_replacer = ' ### '\n",
    "\n",
    "    result = copy.deepcopy(texto)\n",
    "    result = str(result)\n",
    "    \n",
    "    result=result.lower() if to_lower else result\n",
    "    result=result.replace('{html}',\"\") \n",
    "    \n",
    "    result=re.sub(r\"[a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+\", email_replacer, result) if replace_email else result #subtituindo valores de email por 'mail###'\n",
    "    result=re.sub(r\"http\\S+\", url_replacer, result) if replace_url else result #subtituindo urls por 'weblink###'\n",
    "    result=re.sub('\\d', number_replacer, result) if replace_numbers else result #subtituindo números por '###'\n",
    "    \n",
    "    result=re.sub('([.,!?])', r' \\1 ', result)  #colocando espaço entre pontuações de palavras\n",
    "    \n",
    "    # result=result.replace(\"<br />\", \"\")\n",
    "    result=result.replace(\"!\", \" \")\n",
    "    result=result.replace('\"', \" \")\n",
    "    result=result.replace(\"“\", \" \")\n",
    "    result=result.replace(\"”\", \" \")\n",
    "    result=result.replace(\"$\", \" \")\n",
    "    result=result.replace(\"%\", \" \")\n",
    "    result=result.replace(\"&\", \" \")\n",
    "    result=result.replace(\"'\", \" \")\n",
    "    result=result.replace(\"(\", \" \")\n",
    "    result=result.replace(\")\", \" \")\n",
    "    result=result.replace(\"*\", \" \")\n",
    "    result=result.replace(\"+\", \" \")\n",
    "    result=result.replace(\",\", \" \")\n",
    "    result=result.replace(\" - \", \" \")\n",
    "    result=result.replace(\" -\", \" \")\n",
    "    result=result.replace(\" – \", \" \")\n",
    "    result=result.replace(\".\", \" \")\n",
    "    result=result.replace(\"/\", \" \")\n",
    "    result=result.replace(\":\", \" \")\n",
    "    result=result.replace(\";\", \" \")\n",
    "    result=result.replace(\"<\", \" \")\n",
    "    result=result.replace(\"=\", \" \")\n",
    "    result=result.replace(\">\", \" \")\n",
    "    result=result.replace(\"?\", \" \")\n",
    "    result=result.replace(\"@\", \" \")\n",
    "    result=result.replace(\"[\", \" \")\n",
    "    result=result.replace(\"\\\\\", \" \")\n",
    "    result=result.replace(\"]\", \" \")\n",
    "    result=result.replace(\"^\", \" \")\n",
    "    result=result.replace(\" _ \", \" \")\n",
    "    result=result.replace(\"`\", \" \")\n",
    "    result=result.replace(\"{\", \" \")\n",
    "    result=result.replace(\"|\", \" \")\n",
    "    result=result.replace(\"}\", \" \")\n",
    "    result=result.replace(\"~\", \" \")\n",
    "    \n",
    "    result=result.replace(\"§\", \"\")\n",
    "    result=result.replace(\"ª\", \"\")\n",
    "    result=result.replace(\"º\", \"\")\n",
    "    result=result.replace(\"°\", \"\")\n",
    "    \n",
    "    # result=re.sub(' +', ' ', result)\n",
    "    result=unidecode.unidecode(result) if replace_accents else result\n",
    "\n",
    "    result=result.replace(\"\\n\", \" \") #removendo quebras de linha\n",
    "    result=re.sub(r'\\s{2,}', ' ', result) #removendo espaços duplicados\n",
    "    \n",
    "    result=remove_stop_words(result) if replace_stop_words else result\n",
    "    result=re.sub(r'\\b[a-zA-Z]\\s', '', result) #removendo caracteres isolados\n",
    "\n",
    "    return result\n",
    "\n",
    "removers = ['!', '\\'', '“', '”', '$', ' %', '&', '\\'', '(', ')', '*', '+', ',', '-', '–', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '§', 'ª', 'º', '°']\n",
    "\n",
    "def preprocessor(texto):\n",
    "    result = copy.deepcopy(texto)\n",
    "    result = str(result)\n",
    "    result=result.lower()\n",
    "    \n",
    "    email_replacer = ' '\n",
    "    url_replacer = ' '\n",
    "    phone_replacer = ' '\n",
    "    processo_replacer = ' '\n",
    "    currency_replacer = ' '\n",
    "    cep_replacer = ' '\n",
    "    date_replacer = ' '\n",
    "    ordinal_replacer = ' '\n",
    "    number_replacer = ' '\n",
    "\n",
    "    result=re.sub(r\"[a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+\", email_replacer, result) #subtituindo valores de email por coringa\n",
    "    result=re.sub(r\"http\\S+\", url_replacer, result) #subtituindo urls por coringa\n",
    "    result=re.sub(r\"\\d{7}-?\\d{2}.?\\d{4}.?\\d.?\\d{2}.?\\d{4}\", processo_replacer, result) #subtituindo processo por coringa\n",
    "    result=re.sub(r\"([R_r]\\$\\s{0,}?)(\\d{1,3}(\\.\\d{3})*|\\d+)(\\,\\d{2})?\", currency_replacer, result) #subtituindo valor monetário por coringa\n",
    "    result=re.sub(r\"\\(\\d{2}\\)\\s9?\\d{4}-?\\d{4}\", phone_replacer, result) #subtituindo telefone por coringa\n",
    "    result=re.sub(r\"(([0-9]{2}\\.[0-9]{3}-[0-9]{3})|([0-9]{2}[0-9]{3}-[0-9]{3})|([0-9]{8}))\", cep_replacer, result) #subtituindo cep por coringa\n",
    "    result=re.sub(r\"(?:(?:31(\\/|-|\\.)(?:0?[13578]|1[02]))\\1|(?:(?:29|30)(\\/|-|\\.)(?:0?[1,3-9]|1[0-2])\\2))(?:(?:1[6-9]|[2-9]\\d)?\\d{2})$|(?:29(\\/|-|\\.)0?2\\3(?:(?:(?:1[6-9]|[2-9]\\d)?(?:0[48]|[2468][048]|[13579][26])|(?:(?:16|[2468][048]|[3579][26])00))))$|(?:0?[1-9]|1\\d|2[0-8])(\\/|-|\\.)(?:(?:0?[1-9])|(?:1[0-2]))\\4(?:(?:1[6-9]|[2-9]\\d)?\\d{2})$\",\n",
    "        date_replacer, result) #subtituindo data por coringa\n",
    "    result=re.sub(r'(\\d+)(?:ª|a|º|°|\\.)', ordinal_replacer, result) #subtituindo números ordinais por coringa\n",
    "    result=re.sub(r'\\s?\\d+\\s?', number_replacer, result) #subtituindo números por coringa\n",
    "\n",
    "    result=unidecode.unidecode(result)\n",
    "    result = custom_tokenizer(result)\n",
    "    result=[x for x in result if x not in removers] #removendo caracteres isolados\n",
    "\n",
    "    result=\" \".join(result)\n",
    "    result=result.replace(\"\\n\", \" \") #removendo quebras de linha\n",
    "    result=re.sub(r'([[:alnum:]]|_)\\1{2,}', ' ', result) #removendo caracteres com 3 ou mais ocorrencias sequenciais\n",
    "    result=re.sub(r'\\s{2,}', ' ', result) #removendo espaços duplicados\n",
    "    \n",
    "    result=remove_stop_words(result)\n",
    "    result=re.sub(r'\\b[a-zA-Z]\\s', '', result) #removendo caracteres isolados\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texto_clean_pure'] = df['texto'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texto_clean_stemmed'] = df['texto_clean_pure'].apply(stemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texto_clean_lemmatized'] = df['texto_clean_pure'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "CLEAN PURE\n",
      "processo classe processual cumprimento sentenca assunto principal bancarios valor causa exequente rossinalva ribeiro silva rua ivone pinheiro centro boa_vista/rr executado banco bgn s.a. rua antonio lumack monte edificio empresarial center ii s. /boa_viagem recife/pe cep telefone despacho determino intimacao parte executada manifestar acerca pedido relacao possivel saldo remanescente constante ep prazo quinze dias expedientes necessarios cumpra-se comarca boa_vista rr data constante sistema jarbas lacerda miranda juiz direito titular vara_civel assinado digitalmente\n",
      "--------------------------------------------------------------------------------\n",
      "CLEAN STEMMED\n",
      "process cl process cumpr sentenc assunt princip bancari val caus exequ rossinalv rib silv rua ivon pinh centr boa_vista/rr execut banc bgn s.a. rua antoni lumack mont edifici empresar cent ii s. /boa_vi recife/p cep telefon despach determin intimaca part execut manifest acerc ped relaca possi sald remanesc const ep praz quinz dia expedi necessari cumpra-s comarc boa_v rr dat const sistem jarb lacerd mirand juiz direit titul vara_ci assin digit\n",
      "--------------------------------------------------------------------------------\n",
      "CLEAN LEMMATIZED\n",
      "processo classe processual cumprimento sentencar assunto principal bancario valor causa exequente rossinalva ribeiro silva rua ivone pinheiro centro boa_vista / rr executar banco bgn s.a . rua antonio lumack monte edificio empresarial center ii s. /boa_viagem recife / pe cep telefone despacho determinar intimacao parte executar manifestar acerca pedir relacao possivel saldo remanescente constante ep prazo quinze dia expediente necessario cumprar se comarca boa_vista rr data constante sistema jarbas lacerda miranda juiz direito titular vara_civel assinar digitalmente\n"
     ]
    }
   ],
   "source": [
    "#print('ORIGINAL')\n",
    "#print(df['texto'][0])\n",
    "print('-'*80)\n",
    "print('CLEAN PURE')\n",
    "print(df['texto_clean_pure'][0])\n",
    "print('-'*80)\n",
    "print('CLEAN STEMMED')\n",
    "print(df['texto_clean_stemmed'][0])\n",
    "print('-'*80)\n",
    "print('CLEAN LEMMATIZED')\n",
    "print(df['texto_clean_lemmatized'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70200, 21)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove as linhas sem texto\n",
    "\n",
    "df['texto_clean_pure'].replace(' ', np.nan, inplace=True)\n",
    "df.dropna(subset=['texto_clean_pure'], inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_columns = ['texto_clean_pure', 'texto_clean_stemmed', 'texto_clean_lemmatized']\n",
    "\n",
    "#for column in text_columns:\n",
    "  #array_of_words =[]\n",
    "  #final_corpus = []\n",
    "  #for content in list(df[column]):\n",
    "  #  array_of_words.append(content.split())\n",
    "\n",
    "  #bigrams = Phraser(Phrases(array_of_words, min_count=5, threshold=10))\n",
    "  ## bigrams.phrasegrams\n",
    "  #for s in array_of_words:\n",
    "  #    final_corpus.append(' '.join([word for word in bigrams[s]]))  \n",
    "  \n",
    "#  df[column.replace('texto_', 'corpus_')] = df[column]\n",
    "  #print(final_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec_model = Word2Vec(sentences=final_corpus, vector_size=64,\n",
    "#                     sg=1, window=10, epochs=5,\n",
    "#                     min_count=10, workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_n_similarity=3\n",
    "# check_top_words=['processo', 'cumprimento_sentenca', 'assunto_principal', 'dia', 'intimacao', 'parte']\n",
    "\n",
    "# final_corpus\n",
    "\n",
    "#for word in check_top_words:\n",
    "#    print(\"TOP {} palavras similar a '{}': {}\".format(top_n_similarity, word, word2vec_model.wv.most_similar(word, topn=top_n_similarity)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce word vector dimensionality with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne = TSNE(n_components=2, n_iter=1000, random_state=42, init='random', learning_rate=200)\n",
    "# vectors = np.asarray(word2vec_model.wv.vectors)\n",
    "# X_2d = tsne.fit_transform(vectors)\n",
    "# coords_df = pd.DataFrame(X_2d, columns=['x','y'])\n",
    "# coords_df['token'] = word2vec_model.wv.index_to_key\n",
    "\n",
    "# # coords_df.to_csv('clean_mandamus_tsne.csv', index=False)\n",
    "# # coords_df = pd.read_csv('clean_mandamus_tsne.csv')\n",
    "\n",
    "# _ = coords_df.plot.scatter('x', 'y', figsize=(12,12),\n",
    "#                         marker='.', s=10, alpha=0.2)\n",
    "\n",
    "# subset_df = coords_df.sample(n=5000)\n",
    "\n",
    "# output_notebook()\n",
    "# p = figure(plot_width=800, plot_height=800)\n",
    "# _ = p.text(x=subset_df.x, y=subset_df.y, text=subset_df.token)\n",
    "\n",
    "# show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0                               freq_rel\n",
      "desc_natureza_mandado                       \n",
      "Não é Mandado                       0.871211\n",
      "Intimação                           0.041752\n",
      "Citação                             0.033390\n",
      "Intimação de Sentença               0.018590\n",
      "Intimação para Audiência            0.007236\n",
      "Intimação Despacho                  0.006952\n",
      "Citação e Intimação para Audiência  0.004772\n",
      "Penhora e/ou avaliação              0.003148\n",
      "Notificação                         0.003048\n",
      "Busca e Apreensão                   0.002949\n",
      "Alvará de Soltura                   0.002564\n",
      "Prisão                              0.002550\n",
      "Liminar                             0.001026\n",
      "Reintegração de Posse               0.000313\n",
      "Averbação                           0.000114\n",
      "Condução                            0.000071\n",
      "Medida Cautelar                     0.000071\n",
      "Adjudicação                         0.000057\n",
      "Citação por Hora Certa              0.000057\n",
      "Interrogatório                      0.000043\n",
      "Inquirição de Testemunha            0.000028\n",
      "Depoimento Pessoal                  0.000014\n",
      "Busca e Apreensão de Crianças       0.000014\n",
      "Anotação                            0.000014\n",
      "Internação                          0.000014\n"
     ]
    }
   ],
   "source": [
    "# Define todos nos NA para Não é Mandado\n",
    "df['desc_natureza_mandado'] = df['desc_natureza_mandado'].fillna('Não é Mandado')\n",
    "\n",
    "print(pd.crosstab(index=df['desc_natureza_mandado'], columns=\"freq_rel\", normalize=True).sort_values(by=['freq_rel'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0          freq_rel\n",
      "classificacao          \n",
      "Não é Mandado  0.871211\n",
      "Intimação      0.079302\n",
      "Citação        0.033447\n",
      "Outros         0.016040\n"
     ]
    }
   ],
   "source": [
    "# Faz a unificação das classes comuns para Intimação\n",
    "df['classificacao'] = df['desc_natureza_mandado'] \\\n",
    "    .replace(['Intimação de Sentença',  'Intimação para Audiência', 'Intimação Despacho',   'Citação e Intimação para Audiência'], 'Intimação') \\\n",
    "    .replace(['Citação por Hora Certa'], 'Citação') \\\n",
    "    .replace(['Adjudicação', 'Alvará de Soltura', 'Averbação', 'Busca e Apreensão', 'Busca e Apreensão de Crianças', 'Condução', 'Inquirição de Testemunha', 'Interrogatório', 'Liminar', 'Medida Cautelar', 'Notificação', 'Penhora e/ou avaliação', 'Prisão', 'Reintegração de Posse', 'Anotação', 'Depoimento Pessoal', 'Internação'], 'Outros')\n",
    "    \n",
    "print(pd.crosstab(index=df['classificacao'], columns=\"freq_rel\", normalize=True).sort_values(by=['freq_rel'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0              freq_rel\n",
      "categoria_binaria          \n",
      "0                     61159\n",
      "1                      9041\n"
     ]
    }
   ],
   "source": [
    "df['categoria_binaria'] = df['classificacao']\n",
    "df.loc[df['categoria_binaria'] != 'Não é Mandado', 'categoria_binaria'] = 1 #'GM'\n",
    "df.loc[df['categoria_binaria'] == 'Não é Mandado', 'categoria_binaria'] = 0 #'NGM'\n",
    "\n",
    "print(pd.crosstab(index=df['categoria_binaria'], columns=\"freq_rel\", normalize=False).sort_values(by=['freq_rel'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mov_ordem_coddocumento</th>\n",
       "      <th>numero_processo</th>\n",
       "      <th>mov_ordem_datarecebimento</th>\n",
       "      <th>mov_ordem_login</th>\n",
       "      <th>ad_mov_ordem_magistrado_caminho</th>\n",
       "      <th>ad_mov_ordem_magistrado_descricao</th>\n",
       "      <th>cod_vara</th>\n",
       "      <th>nome_vara</th>\n",
       "      <th>competencia_vara</th>\n",
       "      <th>cod_natureza_mandado</th>\n",
       "      <th>...</th>\n",
       "      <th>ad_mov_exped_mandado_descricao</th>\n",
       "      <th>parte_nome</th>\n",
       "      <th>parte_tipo</th>\n",
       "      <th>i</th>\n",
       "      <th>texto</th>\n",
       "      <th>texto_clean_pure</th>\n",
       "      <th>texto_clean_stemmed</th>\n",
       "      <th>texto_clean_lemmatized</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>categoria_binaria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18597402</td>\n",
       "      <td>9.182751e+18</td>\n",
       "      <td>2018-01-18 18:17:33.783</td>\n",
       "      <td>jarbas.miranda</td>\n",
       "      <td>/2018/jan/28/f/28f20f8e2c5836646c700ff891f5734...</td>\n",
       "      <td>mero expediente</td>\n",
       "      <td>1001064</td>\n",
       "      <td>4ª Vara Cível</td>\n",
       "      <td>VarCiv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>\\nProcesso: 0918275-13.2009.8.23.0010\\nClass...</td>\n",
       "      <td>processo classe processual cumprimento sentenc...</td>\n",
       "      <td>process cl process cumpr sentenc assunt princi...</td>\n",
       "      <td>processo classe processual cumprimento sentenc...</td>\n",
       "      <td>Não é Mandado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31665675</td>\n",
       "      <td>1.317360e+17</td>\n",
       "      <td>2021-08-05 14:20:52.762</td>\n",
       "      <td>daniel</td>\n",
       "      <td>/2021/ago/22/8/2280a179f0d3f298136c2ba7a0c7cc0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6017026</td>\n",
       "      <td>2ª Vara Criminal</td>\n",
       "      <td>VarCrim</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Citação</td>\n",
       "      <td>CARLOS EDUARDO CAVALCANTI DE SANTANA</td>\n",
       "      <td>PROMOVIDO</td>\n",
       "      <td>1</td>\n",
       "      <td>\\nProc. n.° $processo.getNumeroProcessoForma...</td>\n",
       "      <td>proc n.deg processo.getnumeroprocessoformatado...</td>\n",
       "      <td>proc n.deg processo.getnumeroprocessoformat de...</td>\n",
       "      <td>proc n.deg processo.getnumeroprocessoformatado...</td>\n",
       "      <td>Citação</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23681708</td>\n",
       "      <td>8.189782e+18</td>\n",
       "      <td>2019-06-10 12:06:45.934</td>\n",
       "      <td>paulo</td>\n",
       "      <td>/2019/jun/61/1/611c3b714233f31fc3e0300630473c3...</td>\n",
       "      <td>Despacho</td>\n",
       "      <td>1086073</td>\n",
       "      <td>2ª Vara de Família</td>\n",
       "      <td>VarFam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2familia@tjrr.jus.br\\n \\nProc. n.° 0818978-19...</td>\n",
       "      <td>proc n.deg despacho inventariante apresente pr...</td>\n",
       "      <td>proc n.deg despach inventari apres praz dia ul...</td>\n",
       "      <td>proc n.deg despacho inventariante apresente pr...</td>\n",
       "      <td>Não é Mandado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30970967</td>\n",
       "      <td>1.350481e+17</td>\n",
       "      <td>2021-06-07 22:27:52.729</td>\n",
       "      <td>daniel</td>\n",
       "      <td>/2021/jun/fd/b/fdb0731c9cc3e8e48095df897ec5168...</td>\n",
       "      <td>Despacho</td>\n",
       "      <td>1086016</td>\n",
       "      <td>1ª Vara de Família</td>\n",
       "      <td>VarFam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>\\nProcesso: 0013504-81.2010.8.23.0010\\nClass...</td>\n",
       "      <td>processo classe processual inventario assunto ...</td>\n",
       "      <td>process cl process inventari assunt princip in...</td>\n",
       "      <td>processo classe processual inventario assunto ...</td>\n",
       "      <td>Não é Mandado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074336</td>\n",
       "      <td>8.151748e+18</td>\n",
       "      <td>2017-07-19 15:57:23.749</td>\n",
       "      <td>dias.eduardo</td>\n",
       "      <td>/2017/jul/00/e/00ed26bd43ebf8622fd8b90335f30a9...</td>\n",
       "      <td>Despacho</td>\n",
       "      <td>6017022</td>\n",
       "      <td>5ª Vara Cível</td>\n",
       "      <td>VarCiv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>\\nProc. n.° 0815174-77.2017.8.23.0010\\n \\n \\...</td>\n",
       "      <td>proc n.deg despacho intime-se autor derradeira...</td>\n",
       "      <td>proc n.deg despach intime-s autor derr vez pra...</td>\n",
       "      <td>proc n.deg despacho intime-se autor derradeira...</td>\n",
       "      <td>Não é Mandado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mov_ordem_coddocumento  numero_processo mov_ordem_datarecebimento  \\\n",
       "0                18597402     9.182751e+18   2018-01-18 18:17:33.783   \n",
       "1                31665675     1.317360e+17   2021-08-05 14:20:52.762   \n",
       "2                23681708     8.189782e+18   2019-06-10 12:06:45.934   \n",
       "3                30970967     1.350481e+17   2021-06-07 22:27:52.729   \n",
       "4                17074336     8.151748e+18   2017-07-19 15:57:23.749   \n",
       "\n",
       "  mov_ordem_login                    ad_mov_ordem_magistrado_caminho  \\\n",
       "0  jarbas.miranda  /2018/jan/28/f/28f20f8e2c5836646c700ff891f5734...   \n",
       "1          daniel  /2021/ago/22/8/2280a179f0d3f298136c2ba7a0c7cc0...   \n",
       "2           paulo  /2019/jun/61/1/611c3b714233f31fc3e0300630473c3...   \n",
       "3          daniel  /2021/jun/fd/b/fdb0731c9cc3e8e48095df897ec5168...   \n",
       "4    dias.eduardo  /2017/jul/00/e/00ed26bd43ebf8622fd8b90335f30a9...   \n",
       "\n",
       "  ad_mov_ordem_magistrado_descricao  cod_vara           nome_vara  \\\n",
       "0                   mero expediente   1001064       4ª Vara Cível   \n",
       "1                               NaN   6017026    2ª Vara Criminal   \n",
       "2                          Despacho   1086073  2ª Vara de Família   \n",
       "3                          Despacho   1086016  1ª Vara de Família   \n",
       "4                          Despacho   6017022       5ª Vara Cível   \n",
       "\n",
       "  competencia_vara  cod_natureza_mandado  ... ad_mov_exped_mandado_descricao  \\\n",
       "0           VarCiv                   NaN  ...                            NaN   \n",
       "1          VarCrim                  10.0  ...                        Citação   \n",
       "2           VarFam                   NaN  ...                            NaN   \n",
       "3           VarFam                   NaN  ...                            NaN   \n",
       "4           VarCiv                   NaN  ...                            NaN   \n",
       "\n",
       "                             parte_nome parte_tipo  i  \\\n",
       "0                                   NaN        NaN  1   \n",
       "1  CARLOS EDUARDO CAVALCANTI DE SANTANA  PROMOVIDO  1   \n",
       "2                                   NaN        NaN  1   \n",
       "3                                   NaN        NaN  1   \n",
       "4                                   NaN        NaN  1   \n",
       "\n",
       "                                               texto  \\\n",
       "0    \\nProcesso: 0918275-13.2009.8.23.0010\\nClass...   \n",
       "1    \\nProc. n.° $processo.getNumeroProcessoForma...   \n",
       "2   2familia@tjrr.jus.br\\n \\nProc. n.° 0818978-19...   \n",
       "3    \\nProcesso: 0013504-81.2010.8.23.0010\\nClass...   \n",
       "4    \\nProc. n.° 0815174-77.2017.8.23.0010\\n \\n \\...   \n",
       "\n",
       "                                    texto_clean_pure  \\\n",
       "0  processo classe processual cumprimento sentenc...   \n",
       "1  proc n.deg processo.getnumeroprocessoformatado...   \n",
       "2  proc n.deg despacho inventariante apresente pr...   \n",
       "3  processo classe processual inventario assunto ...   \n",
       "4  proc n.deg despacho intime-se autor derradeira...   \n",
       "\n",
       "                                 texto_clean_stemmed  \\\n",
       "0  process cl process cumpr sentenc assunt princi...   \n",
       "1  proc n.deg processo.getnumeroprocessoformat de...   \n",
       "2  proc n.deg despach inventari apres praz dia ul...   \n",
       "3  process cl process inventari assunt princip in...   \n",
       "4  proc n.deg despach intime-s autor derr vez pra...   \n",
       "\n",
       "                              texto_clean_lemmatized  classificacao  \\\n",
       "0  processo classe processual cumprimento sentenc...  Não é Mandado   \n",
       "1  proc n.deg processo.getnumeroprocessoformatado...        Citação   \n",
       "2  proc n.deg despacho inventariante apresente pr...  Não é Mandado   \n",
       "3  processo classe processual inventario assunto ...  Não é Mandado   \n",
       "4  proc n.deg despacho intime-se autor derradeira...  Não é Mandado   \n",
       "\n",
       "  categoria_binaria  \n",
       "0                 0  \n",
       "1                 1  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"../dados/amostra.sample.final{'.full' if ALL_DATA else ''}.csv\", index=False, encoding='utf-8', quotechar='\"',\n",
    "          quoting=csv.QUOTE_NONNUMERIC, escapechar='\\\\')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e99eb1728f8c1d324c385629a52913aa159c2c0ce78b3233732d363a13709a03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
